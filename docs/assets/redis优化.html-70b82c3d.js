import{_ as a,X as e,Y as i,Z as s,a1 as p,$ as l,a2 as c,C as t}from"./framework-0b23a550.js";const d={},o={class:"hint-container tip"},r=s("p",{class:"hint-container-title"},"参考",-1),u={href:"https://pdai.tech/md/db/nosql-redis/db-redis-x-performance.html",target:"_blank",rel:"noopener noreferrer"},m=c(`<h2 id="redis真的变慢了" tabindex="-1"><a class="header-anchor" href="#redis真的变慢了" aria-hidden="true">#</a> Redis真的变慢了</h2><h2 id="什么是基准性能" tabindex="-1"><a class="header-anchor" href="#什么是基准性能" aria-hidden="true">#</a> 什么是基准性能</h2><p><code>Redis</code> 在生产环境服务器上的基准性能，才能进一步评估，当其延迟达到什么程度时，才认为 <code>Redis</code> 确实变慢了</p><p>具体如何做？</p><p>为了避免业务服务器到 Redis 服务器之间的网络延迟，你需要直接在 Redis 服务器上测试实例的响应延迟情况。执行以下命令，就可以测试出这个实例 60 秒内的最大响应延迟：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>
$ redis-cli <span class="token parameter variable">-h</span> <span class="token number">127.0</span>.0.1 <span class="token parameter variable">-p</span> <span class="token number">6379</span> --intrinsic-latency <span class="token number">60</span>
Max latency so far: <span class="token number">1</span> microseconds.
Max latency so far: <span class="token number">15</span> microseconds.
Max latency so far: <span class="token number">17</span> microseconds.
Max latency so far: <span class="token number">18</span> microseconds.
Max latency so far: <span class="token number">31</span> microseconds.
Max latency so far: <span class="token number">32</span> microseconds.
Max latency so far: <span class="token number">59</span> microseconds.
Max latency so far: <span class="token number">72</span> microseconds.
 
<span class="token number">1428669267</span> total runs <span class="token punctuation">(</span>avg latency: <span class="token number">0.0420</span> microseconds / <span class="token number">42.00</span> nanoseconds per run<span class="token punctuation">)</span>.
Worst run took 1429x longer than the average latency.

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>从输出结果可以看到，这 60 秒内的最大响应延迟为 72 微秒（0.072毫秒）。</p><p>你还可以使用以下命令，查看一段时间内 Redis 的最小、最大、平均访问延迟：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>$ redis-cli <span class="token parameter variable">-h</span> <span class="token number">127.0</span>.0.1 <span class="token parameter variable">-p</span> <span class="token number">6379</span> --latency-history <span class="token parameter variable">-i</span> <span class="token number">1</span>
min: <span class="token number">0</span>, max: <span class="token number">1</span>, avg: <span class="token number">0.13</span> <span class="token punctuation">(</span><span class="token number">100</span> samples<span class="token punctuation">)</span> -- <span class="token number">1.01</span> seconds range
min: <span class="token number">0</span>, max: <span class="token number">1</span>, avg: <span class="token number">0.12</span> <span class="token punctuation">(</span><span class="token number">99</span> samples<span class="token punctuation">)</span> -- <span class="token number">1.01</span> seconds range
min: <span class="token number">0</span>, max: <span class="token number">1</span>, avg: <span class="token number">0.13</span> <span class="token punctuation">(</span><span class="token number">99</span> samples<span class="token punctuation">)</span> -- <span class="token number">1.01</span> seconds range
min: <span class="token number">0</span>, max: <span class="token number">1</span>, avg: <span class="token number">0.10</span> <span class="token punctuation">(</span><span class="token number">99</span> samples<span class="token punctuation">)</span> -- <span class="token number">1.01</span> seconds range
min: <span class="token number">0</span>, max: <span class="token number">1</span>, avg: <span class="token number">0.13</span> <span class="token punctuation">(</span><span class="token number">98</span> samples<span class="token punctuation">)</span> -- <span class="token number">1.00</span> seconds range
min: <span class="token number">0</span>, max: <span class="token number">1</span>, avg: <span class="token number">0.08</span> <span class="token punctuation">(</span><span class="token number">99</span> samples<span class="token punctuation">)</span> -- <span class="token number">1.01</span> seconds range
<span class="token punctuation">..</span>.

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>以上输出结果是，每间隔 1 秒，采样 Redis 的平均操作耗时，其结果分布在 0.08 ~ 0.13 毫秒之间。了解了基准性能测试方法，那么你就可以按照以下几步，来判断你的 Redis 是否真的变慢了：在相同配置的服务器上，测试一个正常 Redis 实例的基准性能找到你认为可能变慢的 Redis 实例，测试这个实例的基准性能如果你观察到，这个实例的运行延迟是正常 Redis 基准性能的 2 倍以上，即可认为这个 Redis 实例确实变慢了</p><h2 id="使用复杂度过高的命令" tabindex="-1"><a class="header-anchor" href="#使用复杂度过高的命令" aria-hidden="true">#</a> 使用复杂度过高的命令</h2><p>Redis 提供了慢日志命令的统计功能，它记录了有哪些命令在执行时耗时比较久。查看 Redis 慢日志之前，你需要设置慢日志的阈值。例如，设置慢日志的阈值为 5 毫秒，并且保留最近 500 条慢日志记录：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 命令执行耗时超过 5 毫秒，记录慢日志</span>
CONFIG SET slowlog-log-slower-than <span class="token number">5000</span>
<span class="token comment"># 只保留最近 500 条慢日志</span>
CONFIG SET slowlog-max-len <span class="token number">500</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>此时，你可以执行以下命令，就可以查询到最近记录的慢日志：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> SLOWLOG get <span class="token number">5</span>
<span class="token number">1</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">32693</span>       <span class="token comment"># 慢日志ID</span>
   <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1593763337</span>  <span class="token comment"># 执行时间戳</span>
   <span class="token number">3</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">5299</span>        <span class="token comment"># 执行耗时(微秒)</span>
   <span class="token number">4</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">&quot;LRANGE&quot;</span>           <span class="token comment"># 具体执行的命令和参数</span>
      <span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">&quot;user_list:2000&quot;</span>
      <span class="token number">3</span><span class="token punctuation">)</span> <span class="token string">&quot;0&quot;</span>
      <span class="token number">4</span><span class="token punctuation">)</span> <span class="token string">&quot;-1&quot;</span>
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">32692</span>
   <span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">1593763337</span>
   <span class="token number">3</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">5044</span>
   <span class="token number">4</span><span class="token punctuation">)</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token string">&quot;GET&quot;</span>
      <span class="token number">2</span><span class="token punctuation">)</span> <span class="token string">&quot;user_info:1000&quot;</span>
<span class="token punctuation">..</span>.

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果你的应用程序执行的 <code>Redis</code> 命令有以下特点，那么有可能会导致操作延迟变大：经常使用 <code>O(N)</code> 以上复杂度的命令，例如 <code>SORT、SUNION、ZUNIONSTORE</code> 聚合类命令使用 <code>O(N)</code> 复杂度的命令，但 <code>N</code> 的值非常大第一种情况导致变慢的原因在于，<code>Redis</code> 在操作内存数据时，时间复杂度过高，要花费更多的 <code>CPU</code> 资源。第二种情况导致变慢的原因在于，<code>Redis</code> 一次需要返回给客户端的数据过多，更多时间花费在数据协议的组装和网络传输过程中。</p><h2 id="操作bigkey" tabindex="-1"><a class="header-anchor" href="#操作bigkey" aria-hidden="true">#</a> 操作bigkey</h2><p>如果你查询慢日志发现，并不是复杂度过高的命令导致的，而都是 <code>SET / DEL</code> 这种简单命令出现在慢日志中，那么你就要怀疑你的实例否写入了 <code>bigkey</code>。</p><p>Redis 在写入数据时，需要为新的数据分配内存，相对应的，当从 Redis 中删除数据时，它会释放对应的内存空间。如果一个 key 写入的 value 非常大，那么 Redis 在分配内存时就会比较耗时。同样的，当删除这个 key 时，释放内存也会比较耗时，这种类型的 key 我们一般称之为 bigkey。此时，你需要检查你的业务代码，是否存在写入 bigkey 的情况。你需要评估写入一个 key 的数据大小，尽量避免一个 key 存入过大的数据。</p><p>Redis 提供了扫描 bigkey 的命令，执行以下命令就可以扫描出，一个实例中 bigkey 的分布情况，输出结果是以类型维度展示的</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>$ redis-cli <span class="token parameter variable">-h</span> <span class="token number">127.0</span>.0.1 <span class="token parameter variable">-p</span> <span class="token number">6379</span> <span class="token parameter variable">--bigkeys</span> <span class="token parameter variable">-i</span> <span class="token number">0.01</span>
<span class="token punctuation">..</span>.
-------- summary -------
 
Sampled <span class="token number">829675</span> keys <span class="token keyword">in</span> the keyspace<span class="token operator">!</span>
Total key length <span class="token keyword">in</span> bytes is <span class="token number">10059825</span> <span class="token punctuation">(</span>avg len <span class="token number">12.13</span><span class="token punctuation">)</span>
 
Biggest string found <span class="token string">&#39;key:291880&#39;</span> has <span class="token number">10</span> bytes
Biggest   list found <span class="token string">&#39;mylist:004&#39;</span> has <span class="token number">40</span> items
Biggest    <span class="token builtin class-name">set</span> found <span class="token string">&#39;myset:2386&#39;</span> has <span class="token number">38</span> members
Biggest   <span class="token builtin class-name">hash</span> found <span class="token string">&#39;myhash:3574&#39;</span> has <span class="token number">37</span> fields
Biggest   zset found <span class="token string">&#39;myzset:2704&#39;</span> has <span class="token number">42</span> members
 
<span class="token number">36313</span> strings with <span class="token number">363130</span> bytes <span class="token punctuation">(</span>04.38% of keys, avg size <span class="token number">10.00</span><span class="token punctuation">)</span>
<span class="token number">787393</span> lists with <span class="token number">896540</span> items <span class="token punctuation">(</span><span class="token number">94.90</span>% of keys, avg size <span class="token number">1.14</span><span class="token punctuation">)</span>
<span class="token number">1994</span> sets with <span class="token number">40052</span> members <span class="token punctuation">(</span>00.24% of keys, avg size <span class="token number">20.09</span><span class="token punctuation">)</span>
<span class="token number">1990</span> hashs with <span class="token number">39632</span> fields <span class="token punctuation">(</span>00.24% of keys, avg size <span class="token number">19.92</span><span class="token punctuation">)</span>
<span class="token number">1985</span> zsets with <span class="token number">39750</span> members <span class="token punctuation">(</span>00.24% of keys, avg size <span class="token number">20.03</span><span class="token punctuation">)</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>其实，使用这个命令的原理，就是 <code>Redis</code> 在内部执行了 <code>SCAN</code> 命令，遍历整个实例中所有的 <code>key</code>，然后针对 <code>key</code> 的类型，分别执行 <code>STRLEN、LLEN、HLEN、SCARD、ZCARD</code> 命令，来获取 <code>String</code> 类型的长度、容器类型<code>（List、Hash、Set、ZSet）</code>的元素个数。这里我需要提醒你的是，当执行这个命令时，要注意 2 个问题：对线上实例进行 <code>bigkey</code> 扫描时，<code>Redis</code> 的 OPS 会突增，为了降低扫描过程中对 Redis 的影响，最好控制一下扫描的频率，指定 -i 参数即可，它表示扫描过程中每次扫描后休息的时间间隔，单位是秒扫描结果中，对于容器类型<code>（List、Hash、Set、ZSet）</code>的 key，只能扫描出元素最多的 key。但一个 key 的元素多，不一定表示占用内存也多，你还需要根据业务情况，进一步评估内存占用情况</p><p>那针对 bigkey 导致延迟的问题，有什么好的解决方案呢？</p><p>这里有两点可以优化：</p><p>业务应用尽量避免写入 <code>bigkey</code></p><p>如果你使用的 Redis 是 4.0 以上版本，用 UNLINK 命令替代 DEL，此命令可以把释放 key 内存的操作，放到后台线程中去执行，从而降低对 Redis 的影响</p><p>如果你使用的 Redis 是 6.0 以上版本，<u>可以开启 lazy-free 机制（lazyfree-lazy-user-del = yes），在执行 DEL 命令时，释放内存也会放到后台线程中执行</u>但即便可以使用方案</p><p>2，我也不建议你在实例中存入 bigkey。这是因为 bigkey 在很多场景下，依旧会产生性能问题。例如，bigkey 在分片集群模式下，对于数据的迁移也会有性能影响，以及我后面即将讲到的数据过期、数据淘汰、透明大页，都会受到 bigkey 的影响。</p><h2 id="集中过期" tabindex="-1"><a class="header-anchor" href="#集中过期" aria-hidden="true">#</a> 集中过期</h2><p>如果你发现，平时在操作 Redis 时，并没有延迟很大的情况发生，但在某个时间点突然出现一波延时，</p><p>其现象表现为：变慢的时间点很有规律，例如某个整点，或者每间隔多久就会发生一波延迟。如果是出现这种情况，</p><p>那么你需要排查一下，业务代码中是否存在设置大量 key 集中过期的情况。</p><p>为什么集中过期会导致 Redis 延迟变大？</p><p>这就需要我们了解 Redis 的过期策略是怎样的。</p><p>Redis 的过期数据采用 被动过期 + 主动过期 两种策略：</p><p>被动过期：只有当访问某个 key 时，才判断这个 key 是否已过期，如果已过期，则从实例中删除</p><p>主动过期：Redis 内部维护了一个定时任务，默认每隔 100 毫秒（1秒10次）就会从全局的过期哈希表中随机取出 20 个 key，然后删除其中过期的 key，如果过期 key 的比例超过了 25%，则继续重复此过程，直到过期 key 的比例下降到 25% 以下，或者这次任务的执行耗时超过了 25 毫秒，才会退出循环注意，这个主动过期 key 的定时任务，是在 Redis 主线程中执行的。</p><h2 id="实例内存达到上限" tabindex="-1"><a class="header-anchor" href="#实例内存达到上限" aria-hidden="true">#</a> 实例内存达到上限</h2><p>如果你的 Redis 实例设置了内存上限 maxmemory，那么也有可能导致 Redis 变慢。</p><p>当我们把 Redis 当做纯缓存使用时，通常会给这个实例设置一个内存上限 maxmemory，</p><p>然后设置一个数据淘汰策略。而当实例的内存达到了 maxmemory 后，你可能会发现，在此之后每次写入新数据，操作延迟变大了。</p><p>这是为什么？</p><p>原因在于，当 Redis 内存达到 <code>maxmemory</code> 后，每次写入新的数据之前，<u>Redis 必须先从实例中踢出一部分数据</u>，让整个实例的内存维持在 <code>maxmemory</code> 之下，然后才能把新数据写进来。这个踢出旧数据的逻辑也是需要消耗时间的，而具体耗时的长短，要取决于你配置的淘汰策略：</p><ul><li>allkeys-lru：不管 key 是否设置了过期，淘汰最近最少访问的key</li><li>allkeys-random：不管 key 是否设置了过期，随机淘汰 key</li><li>volatile-lru：只淘汰最近最少访问、并设置了过期时间的</li><li>volatile-random：只随机淘汰设置了过期时间的 key</li><li>allkeys-ttl：不管 key 是否设置了过期，淘汰即将过期的 key</li><li>noeviction：不淘汰任何 key，实例内存达到 maxmeory 后，再写入新数据直接返回错误key</li><li>allkeys-lfu：不管 key 是否设置了过期，淘汰访问频率最低的 key（4.0+版本支持）</li><li>volatile-lfu：只淘汰访问频率最低、并设置了过期时间 key（4.0+版本支持）</li></ul><p>针对这种情况，如何解决呢？ 我给你 4 个方面的优化建议：</p><p>避免存储 bigkey，降低释放内存的耗时</p><p>淘汰策略改为随机淘汰，随机淘汰比 LRU 要快很多（视业务情况调整）</p><p>拆分实例，把淘汰 key 的压力分摊到多个实例上</p><p>如果使用的是 <code>Redis 4.0</code> 以上版本，开启 <code>layz-free</code> 机制，<u>把淘汰 <code>key</code> 释放内存的操作放到后台线程中执行（配置 lazyfree-lazy-eviction = yes）</u></p><h2 id="开启内存大页" tabindex="-1"><a class="header-anchor" href="#开启内存大页" aria-hidden="true">#</a> 开启内存大页</h2><p>什么是内存大页？我们都知道，应用程序向操作系统申请内存时，是按内存页进行申请的，<u>而常规的内存页大小是 4KB</u>。</p><p>Linux 内核从 2.6.38 开始，支持了内存大页机制，<u>该机制允许应用程序以 2MB 大小为单位，向操作系统申请内存</u>。 应用程序每次向操作系统申请的<u>内存单位变大了，但这也意味着申请内存的耗时变长</u></p><p>那如何解决这个问题？</p><p>很简单，你只需要关闭内存大页机制就可以了。</p><p>首先，你需要查看 Redis 机器是否开启了内存大页：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>
$ <span class="token function">cat</span> /sys/kernel/mm/transparent_hugepage/enabled

<span class="token punctuation">[</span>always<span class="token punctuation">]</span> madvise never

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果输出选项是 always，就表示目前开启了内存大页机制，我们需要关掉它：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code> $ <span class="token builtin class-name">echo</span> never <span class="token operator">&gt;</span> /sys/kernel/mm/transparent_hugepage/enabled
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>其实，操作系统提供的内存大页机制，其优势是，可以在一定程序上降低应用程序申请内存的次数。但是对于 Redis 这种对性能和延迟极其敏感的数据库来说，我们希望 Redis 在每次申请内存时，耗时尽量短，所以我不建议你在 Redis 机器上开启这个机制。</p><h2 id="开启aof" tabindex="-1"><a class="header-anchor" href="#开启aof" aria-hidden="true">#</a> 开启AOF</h2><p>为了保证 AOF 文件数据的安全性，Redis 提供了 3 种刷盘机制：</p><ul><li><p>appendfsync always：主线程每次执行写操作后立即刷盘，此方案会占用比较大的磁盘 IO 资源，但数据安全性最高</p></li><li><p>appendfsync no：主线程每次写操作只写内存就返回，内存数据什么时候刷到磁盘，交由操作系统决定，此方案对性能影响最小，但数据安全性也最低，Redis 宕机时丢失的数据取决于操作系统刷盘时机</p></li><li><p>appendfsync everysec：主线程每次写操作只写内存就返回，然后由后台线程每隔 1 秒执行一次刷盘操作（触发fsync系统调用），此方案对性能影响相对较小，但当 Redis 宕机时会丢失 1 秒的数据</p></li></ul><p>下面我们依次来分析，这几个机制对性能的影响。</p><p>如果你的 AOF 配置为 <code>appendfsync always</code>，那么 Redis 每处理一次写操作，都会把这个命令写入到磁盘中才返回，整个过程都是在主线程执行的，这个过程必然会加重 Redis 写负担。原因也很简单，操作磁盘要比操作内存慢几百倍，采用这个配置会严重拖慢 Redis 的性能，因此我不建议你把 AOF 刷盘方式配置为 always。</p><p>我们接着来看 <code>appendfsync no</code> 配置项。在这种配置下，Redis 每次写操作只写内存，什么时候把内存中的数据刷到磁盘，交给操作系统决定，此方案对 Redis 的性能影响最小，但当 Redis 宕机时，会丢失一部分数据，为了数据的安全性，一般我们也不采取这种配置。</p><p><u>如果你的 Redis 只用作纯缓存，对于数据丢失不敏感，采用配置 <code>appendfsync no</code> 也是可以的。</u></p><h2 id="绑定cpu" tabindex="-1"><a class="header-anchor" href="#绑定cpu" aria-hidden="true">#</a> 绑定CPU</h2><p>如何再进一步优化？可能你已经想到了，我们是否可以让主线程、子进程、后台线程，分别绑定在固定的 CPU 核心上，不让它们来回切换，这样一来，他们各自使用的 CPU 资源互不影响。其实，这个方案 Redis 官方已经想到了。Redis 在 6.0 版本已经推出了这个功能，我们可以通过以下配置，对主线程、后台线程、后台 RDB 进程、AOF rewrite 进程，绑定固定的 CPU 逻辑核心：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># Redis Server 和 IO 线程绑定到 CPU核心 0,2,4,6</span>
server_cpulist <span class="token number">0</span>-7:2
 
<span class="token comment"># 后台子线程绑定到 CPU核心 1,3</span>
bio_cpulist <span class="token number">1,3</span>
 
<span class="token comment"># 后台 AOF rewrite 进程绑定到 CPU 核心 8,9,10,11</span>
aof_rewrite_cpulist <span class="token number">8</span>-11
 
<span class="token comment"># 后台 RDB 进程绑定到 CPU 核心 1,10,11</span>
<span class="token comment"># bgsave_cpulist 1,10-1</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="使用swap" tabindex="-1"><a class="header-anchor" href="#使用swap" aria-hidden="true">#</a> 使用Swap</h2><p>什么是 Swap？为什么使用 Swap 会导致 Redis 的性能下降？如果你对操作系统有些了解，就会知道操作系统为了缓解内存不足对应用程序的影响，允许把一部分内存中的数据换到磁盘上，以达到应用程序对内存使用的缓冲，这些内存数据被换到磁盘上的区域，就是 Swap。问题就在于，当内存中的数据被换到磁盘上后，Redis 再访问这些数据时，就需要从磁盘上读取，访问磁盘的速度要比访问内存慢几百倍！</p><p>你可以通过以下方式来查看 Redis 进程是否使用到了 Swap：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>
<span class="token comment"># 先找到 Redis 的进程 ID</span>
$ <span class="token function">ps</span> <span class="token parameter variable">-aux</span> <span class="token operator">|</span> <span class="token function">grep</span> redis-server
 
<span class="token comment"># 查看 Redis Swap 使用情况</span>
$ <span class="token function">cat</span> /proc/<span class="token variable">$pid</span>/smaps <span class="token operator">|</span> <span class="token function">egrep</span> <span class="token string">&#39;^(Swap|Size)&#39;</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>输出结果如下：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>Size:               <span class="token number">1256</span> kB
Swap:                  <span class="token number">0</span> kB
Size:                  <span class="token number">4</span> kB
Swap:                  <span class="token number">0</span> kB
Size:                <span class="token number">132</span> kB
Swap:                  <span class="token number">0</span> kB
Size:              <span class="token number">63488</span> kB
Swap:                  <span class="token number">0</span> kB
Size:                <span class="token number">132</span> kB
Swap:                  <span class="token number">0</span> kB
Size:              <span class="token number">65404</span> kB
Swap:                  <span class="token number">0</span> kB
Size:            <span class="token number">1921024</span> kB
Swap:                  <span class="token number">0</span> kB
<span class="token punctuation">..</span>.
------

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这个结果会列出 Redis 进程的内存使用情况。每一行 Size 表示 Redis 所用的一块内存大小，Size 下面的 Swap 就表示这块 Size 大小的内存，有多少数据已经被换到磁盘上了，如果这两个值相等，说明这块内存的数据都已经完全被换到磁盘上了。如果只是少量数据被换到磁盘上，例如每一块 Swap 占对应 Size 的比例很小，那影响并不是很大。如果是几百兆甚至上 GB 的内存被换到了磁盘上，那么你就需要警惕了，这种情况 Redis 的性能肯定会急剧下降。此时的解决方案是：增加机器的内存，让 Redis 有足够的内存可以使用整理内存空间，释放出足够的内存供 Redis 使用，然后释放 Redis 的 Swap，让 Redis 重新使用内存</p><h2 id="碎片整理" tabindex="-1"><a class="header-anchor" href="#碎片整理" aria-hidden="true">#</a> 碎片整理</h2><p>很简单，mem_fragmentation_ratio = used_memory_rss / used_memory。</p><p>其中 used_memory 表示 Redis 存储数据的内存大小，而 used_memory_rss 表示操作系统实际分配给 Redis 进程的大小。</p><p>如果 mem_fragmentation_ratio &gt; 1.5，说明内存碎片率已经超过了 50%，这时我们就需要采取一些措施来降低内存碎片了。</p><p>解决的方案一般如下：如果你使用的是 Redis 4.0 以下版本，只能通过重启实例来解决如果你使用的是 Redis 4.0 版本，它正好提供了自动碎片整理的功能，可以通过配置开启碎片自动整理但是，开启内存碎片整理，它也有可能会导致 Redis 性能下降。原因在于，Redis 的碎片整理工作是也在主线程中执行的，当其进行碎片整理时，必然会消耗 CPU 资源，产生更多的耗时，从而影响到客户端的请求。所以，当你需要开启这个功能时，最好提前测试评估它对 Redis 的影响。</p><p>Redis 碎片整理的参数配置如下：</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 开启自动内存碎片整理（总开关）</span>
activedefrag <span class="token function">yes</span>
 
<span class="token comment"># 内存使用 100MB 以下，不进行碎片整理</span>
active-defrag-ignore-bytes 100mb
 
<span class="token comment"># 内存碎片率超过 10%，开始碎片整理</span>
active-defrag-threshold-lower <span class="token number">10</span>
<span class="token comment"># 内存碎片率超过 100%，尽最大努力碎片整理</span>
active-defrag-threshold-upper <span class="token number">100</span>
 
<span class="token comment"># 内存碎片整理占用 CPU 资源最小百分比</span>
active-defrag-cycle-min <span class="token number">1</span>
<span class="token comment"># 内存碎片整理占用 CPU 资源最大百分比</span>
active-defrag-cycle-max <span class="token number">25</span>
 
<span class="token comment"># 碎片整理期间，对于 List/Set/Hash/ZSet 类型元素一次 Scan 的数量</span>
active-defrag-max-scan-fields <span class="token number">1000</span>

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="网络带宽过载" tabindex="-1"><a class="header-anchor" href="#网络带宽过载" aria-hidden="true">#</a> 网络带宽过载</h2>`,84);function b(v,k){const n=t("ExternalLinkIcon");return e(),i("div",null,[s("div",o,[r,s("p",null,[s("a",u,[p(" Redis进阶 - 性能调优：Redis性能调优详解 "),l(n)])])]),m])}const g=a(d,[["render",b],["__file","redis优化.html.vue"]]);export{g as default};
