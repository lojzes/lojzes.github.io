import{_ as a,X as e,Y as p,Z as n,a1 as c,$ as o,a2 as r,C as l}from"./framework-0b23a550.js";const d={},t={class:"hint-container tip"},u=n("p",{class:"hint-container-title"},"参考",-1),m={href:"https://juejin.cn/post/6949806402743304206",target:"_blank",rel:"noopener noreferrer"},i=r(`<blockquote><p>基于 jdk8 jdk8及以后取消了 -XX:PermSize 和 -XX:MaxPermSize</p></blockquote><h2 id="jvm-调优使用参数" tabindex="-1"><a class="header-anchor" href="#jvm-调优使用参数" aria-hidden="true">#</a> jvm 调优使用参数</h2><h3 id="查看堆内存" tabindex="-1"><a class="header-anchor" href="#查看堆内存" aria-hidden="true">#</a> 查看堆内存</h3><p>1.查看堆总内存 <code>jinfo -flag MaxHeapSize vmid</code></p><p>2.查看新生代内存 <code>jinfo -flag NewSize vmid</code></p><p>3.查看老年代内存 <code>jinfo -flag OldSize vmid</code></p><p>4.查看使用的垃圾收集器 <code>jinfo -flags vmid</code></p><p>5.查看元空间（方法区）内存 <code>jinfo -flag MetaspaceSize（MaxMetaspaceSize） vmid</code></p><h3 id="设置堆内存" tabindex="-1"><a class="header-anchor" href="#设置堆内存" aria-hidden="true">#</a> 设置堆内存</h3><p>1.设置堆最小大小 <code>java -jar -Xms2g xxx.jar</code></p><p>2.设置堆最大大小 <code>java -jar -Xmx2g xxx.jar</code> (建议最大最小内存设置一样)</p><p>3.设置新生代大小 <code>java -jar -XX:NewSize=500m xxx.jar</code>（根据实际情况设置，没特别要求使用<code>默认1/3堆内存</code>即可 ）</p><p>4.设置新生代老年代内存比例 <code>java -jar -XX:NewRatio=3 xxx.jar</code>(默认是2，这个和-XX:NewSize一样，只是一个是比例，一个是实际大小，建议调整比例)</p><p>解释：NewRatio = 3 表示 新生代：老年代 = 1:3 即年轻代占堆的 1/4</p><p>5.设置新生代内存内部 <code>eden</code> 和 <code>survivor</code> 比例 <code>java -jar -XX:SurvivorRatio=6 xxx.jar</code>(默认是8，eden区占新生区内存8/10，survivor占2个1/10 )</p><p>5.设置垃圾收集器 <code>java -jar -XX:+UseParallelGC xxx.jar</code>（不同垃圾回收器不一样，G1是设置region大小）</p><p>6.设置元空间大小 <code>java -jar -XX:MaxMetaspaceSize=500m </code>(也就是方法区大小，存放常量池和类信息)</p><p>说明：一般实际情况设置-Xms和-Xmx设置一样即可，然后如果有需要，设置新生代大小，一般web程序取决于并发量。</p><h3 id="查看内存使用情况" tabindex="-1"><a class="header-anchor" href="#查看内存使用情况" aria-hidden="true">#</a> 查看内存使用情况</h3><p>jstat -gc -h10(多少行重新打印头) vmid 1000(间隔时间ms) 100(打印次数)</p><pre><code>  S0C:survivor0分配空间大小kb
  S1C:survivor1分配空间大小kb
  S0U:survivor0使用空间大小kb
  S1U:survivor1使用空间大小kb
  EC:eden分配空间大小kb大小kb
  EU:eden使用空间大小kb大小kb
  OC：老年代分配空间大小kb
  OU:老年代使用空间大小kb
  MC：方法区分配空间大小kb
  MU:方法区使用空间大小kb
  YGC：年轻代gc次数大小kb
  YGCT：年轻代gc使用时间大小kb
  FGC:老年代gc次数大小kb
  FGCT：老年代gc使用时间大小kb
</code></pre><p>说明：</p><p>1.关注EU使用情况，一般并发高的代码，很快就会占满</p><p>2.和EU关联的就是YGC，看看回收频率，不要太高，会发生stw占用时间长，特别是c端</p><p>3.MC主要是元空间大小，一般使用动态代理，会频繁产生新类，会对这个空间有影响</p><h2 id="案例" tabindex="-1"><a class="header-anchor" href="#案例" aria-hidden="true">#</a> 案例</h2><h2 id="jvm-调优实例" tabindex="-1"><a class="header-anchor" href="#jvm-调优实例" aria-hidden="true">#</a> jvm 调优实例</h2><h3 id="网站流量浏览量暴增后-网站反应页面响很慢" tabindex="-1"><a class="header-anchor" href="#网站流量浏览量暴增后-网站反应页面响很慢" aria-hidden="true">#</a> 网站流量浏览量暴增后，网站反应页面响很慢</h3><p>1、问题推测：在测试环境测速度比较快，但是一到生产就变慢，所以推测可能是因为垃圾收集导致的业务线程停顿。</p><p>2、定位：为了确认推测的正确性，在线上通过<code>jstat -gc</code> 指令 看到<code>JVM</code>进行<code>GC </code>次数频率非常高，<code>GC</code>所占用的时间非常长，所以基本推断就是因为<code>GC</code>频率非常高，所以导致业务线程经常停顿，从而造成网页反应很慢。</p><p>3、解决方案：因为网页访问量很高，所以对象创建速度非常快，导致堆内存容易填满从而频繁<code>GC</code>，所以这里问题在于新生代内存太小，所以这里可以增加<code>JVM</code>内存就行了，所以初步从原来的2G内存增加到16G内存。</p><p>4、第二个问题：增加内存后的确平常的请求比较快了，但是又出现了另外一个问题，就是不定期的会间断性的卡顿，而且单次卡顿的时间要比之前要长很多。</p><p>5、问题推测：联系到是之前的优化加大了内存，所以推测可能是因为内存加大了，从而导致单次GC的时间变长从而导致间接性的卡顿。</p><p>6、定位：还是通过<code>jstat -gc </code>指令 查看到 的确FGC次数并不是很高，但是花费在FGC上的时间是非常高的,根据<code>GC</code>日志 查看到单次<code>FGC</code>的时间有达到几十秒的。</p><p>7、解决方案： 因为<code>JVM</code>默认使用的是PS+PO的组合，<code>PS+PO</code>垃圾标记和收集阶段都是<code>STW</code>，所以内存加大了之后，需要进行垃圾回收的时间就变长了，所以这里要想避免单次<code>GC</code>时间过长，所以需要更换并发类的收集器，因为当前的JDK版本为1.7，所以最后选择CMS垃圾收集器，根据之前垃圾收集情况设置了一个预期的停顿的时间，上线后网站再也没有了卡顿问题。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>➜  JavaVirtualMachines jstat <span class="token parameter variable">-gc</span> <span class="token parameter variable">-t</span> <span class="token number">4828</span>  <span class="token number">2000</span> <span class="token number">10</span>
Timestamp        S0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT
          <span class="token number">234.0</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">236.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">238.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">240.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">242.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">244.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">246.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">248.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">250.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
          <span class="token number">252.1</span> <span class="token number">13312.0</span> <span class="token number">13312.0</span>  <span class="token number">0.0</span>    <span class="token number">0.0</span>   <span class="token number">165888.0</span> <span class="token number">30286.9</span>   <span class="token number">153088.0</span>   <span class="token number">14252.3</span>   <span class="token number">35496.0</span> <span class="token number">32931.5</span> <span class="token number">5032.0</span> <span class="token number">4563.9</span>      <span class="token number">6</span>    <span class="token number">0.046</span>   <span class="token number">2</span>      <span class="token number">0.069</span>    <span class="token number">0.115</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="后台导出数据引发的oom" tabindex="-1"><a class="header-anchor" href="#后台导出数据引发的oom" aria-hidden="true">#</a> 后台导出数据引发的OOM</h3><p>**问题描述：**公司的后台系统，偶发性的引发OOM异常，堆内存溢出。</p><p>1、因为是偶发性的，所以第一次简单的认为就是堆内存不足导致，所以单方面的加大了堆内存从4G调整到8G。</p><p>2、但是问题依然没有解决，只能从堆内存信息下手，通过开启了<code>-XX:+HeapDumpOnOutOfMemoryError</code>参数 获得堆内存的dump文件。</p><p>3、<code>VisualVM </code>对 堆<code>dump</code>文件进行分析，通过VisualVM查看到占用内存最大的对象是String对象，本来想跟踪着<code>String</code>对象找到其引用的地方，但<code>dump</code>文件太大，跟踪进去的时候总是卡死，而<code>String</code>对象占用比较多也比较正常，最开始也没有认定就是这里的问题，于是就从线程信息里面找突破点。</p><p>4、通过线程进行分析，先找到了几个正在运行的业务线程，然后逐一跟进业务线程看了下代码，发现有个引起我注意的方法，导出订单信息。</p><p>5、因为订单信息导出这个方法可能会有几万的数据量，首先要从数据库里面查询出来订单信息，然后把订单信息生成<code>excel</code>，这个过程会产生大量的<code>String</code>对象。</p><p>6、为了验证自己的猜想，于是准备登录后台去测试下，结果在测试的过程中发现到处订单的按钮前端居然没有做点击后按钮置灰交互事件，结果按钮可以一直点，因为导出订单数据本来就非常慢，使用的人员可能发现点击后很久后页面都没反应，结果就一直点，结果就大量的请求进入到后台，堆内存产生了大量的订单对象和EXCEL对象，而且方法执行非常慢，导致这一段时间内这些对象都无法被回收，所以最终导致内存溢出。</p><p>7、知道了问题就容易解决了，最终没有调整任何JVM参数，只是在前端的导出订单按钮上加上了置灰状态，等后端响应之后按钮才可以进行点击，然后减少了查询订单信息的非必要字段来减少生成对象的体积，然后问题就解决了。</p><h3 id="单个缓存数据过大导致的系统cpu飚高" tabindex="-1"><a class="header-anchor" href="#单个缓存数据过大导致的系统cpu飚高" aria-hidden="true">#</a> 单个缓存数据过大导致的系统CPU飚高</h3><p>1、系统发布后发现<code>CPU</code>一直飚高到<code>600%</code>，发现这个问题后首先要做的是定位到是哪个应用占用<code>CPU</code>高，通过<code>top</code> 找到了对应的一个<code>java</code>应用占用<code>CPU</code>资源<code>600%</code>。</p><p>2、如果是应用的<code>CPU</code>飚高，那么基本上可以定位可能是<u>锁资源竞争</u>，或者是<u>频繁<code>GC</code>造成的</u>。</p><p>3、所以准备首先从<code>GC</code>的情况排查，如果GC正常的话再从线程的角度排查，首先使用<code>jstat -gc PID </code>指令打印出GC的信息，结果得到得到的GC 统计信息有明显的异常，应用在运行了才几分钟的情况下GC的时间就占用了482秒，那么问这很明显就是频繁GC导致的CPU飚高。</p><p>4、定位到了是<code>GC</code>的问题，那么下一步就是找到频繁GC的原因了，所以可以从两方面定位了，可能是哪个地方频繁创建对象，或者就是有内存泄露导致内存回收不掉。</p><p>5、根据这个思路决定把堆内存信息dump下来看一下，使用<code>jmap -dump </code>指令把堆内存信息<code>dump</code>下来（堆内存空间大的慎用这个指令否则容易导致会影响应用，因为我们的堆内存空间才2G所以也就没考虑这个问题了）。</p><p>6、把堆内存信息dump下来后，就使用<code>visualVM</code>进行离线分析了，首先从占用内存最多的对象中查找，结果排名第三看到一个业务VO占用堆内存约10%的空间，很明显这个对象是有问题的。</p><p>7、通过业务对象找到了对应的业务代码，通过代码的分析找到了一个可疑之处，这个业务对象是查看新闻资讯信息生成的对象，由于想提升查询的效率，所以把新闻资讯保存到了<code>redis</code>缓存里面，每次调用资讯接口都是从缓存里面获取。</p><p>8、把新闻保存到<code>redis</code>缓存里面这个方式是没有问题的，有问题的是新闻的<code>50000</code>多条数据都是保存在一个<code>key</code>里面，这样就导致每次调用查询新闻接口都会从<code>redis</code>里面把<code>50000</code>多条数据都拿出来，再做筛选分页拿出<code>10</code>条返回给前端。<code>50000</code>多条数据也就意味着会产生<code>50000</code>多个对象，每个对象<code>280</code>个字节左右，<code>50000</code>个对象就有<code>13.3M</code>，这就意味着只要查看一次新闻信息就会产生至少<code>13.3M</code>的对象，那么并发请求量只要到<code>10</code>，那么每秒钟都会产生<code>133M</code>的对象，而这种大对象会被直接分配到老年代，这样的话一个<code>2G</code>大小的老年代内存，只需要几秒就会塞满，从而触发<code>GC</code>。</p><p>9、知道了问题所在后那么就容易解决了，问题是因为单个缓存过大造成的，那么只需要把缓存减小就行了，这里只需要把缓存以页的粒度进行缓存就行了，每个key缓存10条作为返回给前端1页的数据，这样的话每次查询新闻信息只会从缓存拿出10条数据，就避免了此问题的 产生。</p><h3 id="cpu经常100-问题定位" tabindex="-1"><a class="header-anchor" href="#cpu经常100-问题定位" aria-hidden="true">#</a> CPU经常100% 问题定位</h3><p>问题分析：CPU高一定是某个程序长期占用了CPU资源。</p><p>1、所以先需要找出那个进行占用CPU高。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code> <span class="token function">top</span>  列出系统各个进程的资源占用情况。
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>2、然后根据找到对应进行里哪个线程占用CPU高。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code> <span class="token function">top</span> <span class="token parameter variable">-Hp</span> 进程ID   列出对应进程里面的线程占用资源情况
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>3、找到对应线程ID后，再打印出对应线程的堆栈信息</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token builtin class-name">printf</span> <span class="token string">&quot;%x<span class="token entity" title="\\n">\\n</span>&quot;</span>  PID    把线程ID转换为16进制。

jstack PID 打印出进程的所有线程信息，从打印出来的线程信息中找到上一
        步转换为16进制的线程ID对应的线程信息。
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>4、最后根据线程的堆栈信息定位到具体业务方法,从代码逻辑中找到问题所在。</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>查看是否有线程长时间的watting 或blocked
如果线程长期处于watting状态下， 关注watting on xxxxxx，说明线程在等待这把锁，然后根据锁的地址找到持有锁的线程。
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="内存飚高问题定位" tabindex="-1"><a class="header-anchor" href="#内存飚高问题定位" aria-hidden="true">#</a> 内存飚高问题定位</h3><p>分析： 内存飚高如果是发生在java进程上，一般是因为创建了大量对象所导致，持续飚高说明垃圾回收跟不上对象创建的速度，或者内存泄露导致对象无法回收。</p><p>1、先观察垃圾回收的情况</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>
jstat <span class="token parameter variable">-gc</span> PID <span class="token number">1000</span> 查看GC次数，时间等信息，每隔一秒打印一次。
  
jmap <span class="token parameter variable">-histo</span> PID <span class="token operator">|</span> <span class="token function">head</span> <span class="token parameter variable">-20</span>   查看堆内存占用空间最大的前20个对象类型,可初步查看是哪个对象占用了内存。
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>如果每次GC次数频繁，而且每次回收的内存空间也正常，那说明是因为对象创建速度快导致内存一直占用很高；如果每次回收的内存非常少，那么很可能是因为内存泄露导致内存一直无法被回收。</p><p>2、导出堆内存文件快照</p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>
jmap -dump:live,format<span class="token operator">=</span>b,file<span class="token operator">=</span>/home/myheapdump.hprof PID  dump堆内存信息到文件。

</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>3、使用visualVM对dump文件进行离线分析,找到占用内存高的对象，再找到创建该对象的业务代码位置，从代码和业务场景中定位具体问题。</p><h3 id="数据分析平台系统频繁-full-gc" tabindex="-1"><a class="header-anchor" href="#数据分析平台系统频繁-full-gc" aria-hidden="true">#</a> 数据分析平台系统频繁 Full GC</h3><p>平台主要对用户在 App 中行为进行定时分析统计，并支持报表导出，使用 CMS GC 算法。</p><p>数据分析师在使用中发现系统页面打开经常卡顿，通过 jstat 命令发现系统每次 Young GC 后大约有 10% 的存活对象进入老年代。</p><p>原来是因为 Survivor 区空间设置过小，每次 Young GC 后存活对象在 Survivor 区域放不下，提前进入老年代。</p><p>通过调大 Survivor 区，使得 Survivor 区可以容纳 Young GC 后存活对象，对象在 Survivor 区经历多次 Young GC 达到年龄阈值才进入老年代。</p><p>调整之后每次 Young GC 后进入老年代的存活对象稳定运行时仅几百 Kb，Full GC 频率大大降低。</p><h3 id="业务对接网关-oom" tabindex="-1"><a class="header-anchor" href="#业务对接网关-oom" aria-hidden="true">#</a> 业务对接网关 OOM</h3><p>网关主要消费 Kafka 数据，进行数据处理计算然后转发到另外的 Kafka 队列，系统运行几个小时候出现 OOM， 重启系统几个小时之后又 OOM。 通过 jmap 导出堆内存，在 eclipse MAT 工具分析才找出原因：代码中将某个业务 Kafka 的 topic 数据进行日志异步打印， 该业务数据量较大，大量对象堆积在内存中等待被打印，导致 OOM。</p><h3 id="鉴权系统频繁长时间-full-gc" tabindex="-1"><a class="header-anchor" href="#鉴权系统频繁长时间-full-gc" aria-hidden="true">#</a> 鉴权系统频繁长时间 Full GC</h3><p>系统对外提供各种账号鉴权服务，使用时发现系统经常服务不可用，通过 Zabbix 的监控平台监控发现系统频繁发生长时间 Full GC，且触发时老年代的堆内存通常并没有占满，发现原来是业务代码中调用了 System.gc()。</p>`,83);function b(k,v){const s=l("ExternalLinkIcon");return e(),p("div",null,[n("div",t,[u,n("p",null,[n("a",m,[c("【JVM进阶之路】十：JVM调优总结 "),o(s)])])]),i])}const C=a(d,[["render",b],["__file","jvm调优.html.vue"]]);export{C as default};
